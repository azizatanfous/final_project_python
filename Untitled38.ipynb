{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/TV1B0ZpmirQjoK9vog58",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azizatanfous/final_project_python/blob/main/Untitled38.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries \n",
        "import tensorflow as tf #build and deploy machine learning models\n",
        "import tensorflow_hub as hub  #pre-trained machine learning models and reusable code modules\n",
        "import tensorflow_io as tfio #collection of file systems and file formats for TensorFlow\n",
        "import pandas as pd #data manipulation and analysis\n",
        "import numpy as np #numerical computing in Python\n",
        "import librosa #Python package for audio and music signal processing\n",
        "import glob #retrieve files/pathnames that match a specified pattern.\n",
        "import csv\n",
        "import io #functionality for working with input and output streams.\n",
        "from IPython.display import Audio #display audio files in Jupyter notebooks or other IPython environments.\n",
        "from tqdm import tqdm  #add progress bars to loops and other iterables\n",
        "import torchaudio #enables efficient and fast processing of audio signals and supports loading and decoding audio files in various formats\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "metadata": {
        "id": "VyrdqQEU7oQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option \n",
        "df = pd.read_csv('/kaggle/input/birdclef-2023/train_metadata.csv')\n",
        "AUDIO_PATH = Path('/kaggle/input/birdclef-2023/train_audio')\n",
        "model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/TensorFlow2/variations/bird-vocalization-classifier/versions/2')\n",
        "model_labels_df = pd.read_csv(hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/2') + \"/assets/label.csv\")\n",
        "\n",
        "SAMPLE_RATE = 32000\n",
        "WINDOW = 5*SAMPLE_RATE\n",
        "\n",
        "bc2023_labels = sorted(df.primary_label.unique())\n",
        "label_to_index = {v: k for k, v in enumerate(bc2023_labels)}\n",
        "model_labels = {v: k for k, v in enumerate(model_labels_df.ebird2021)}\n",
        "model_bc2023_indexes = [model_labels[label] if label in model_labels else -1 for label in bc2023_labels]"
      ],
      "metadata": {
        "id": "sflMcqrYF3Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pz4K2Wu2GIPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st option\n",
        "#  Explore the training data\n",
        "# Load a sample audio files from two different species\n",
        "audio_abe, sr_abe = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\")\n",
        "audio_abh, sr_abh = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\")"
      ],
      "metadata": {
        "id": "zpoP5Gu4iAFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option\n",
        "import multiprocessing as mp\n",
        "import librosa\n",
        "\n",
        "# Define a function to load audio files\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path)\n",
        "    return audio, sr\n",
        "\n",
        "# Define the file paths\n",
        "file_paths = [\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\",\n",
        "              \"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\"]\n",
        "\n",
        "# Create a pool of worker processes\n",
        "pool = mp.Pool()\n",
        "\n",
        "# Load the audio files in parallel\n",
        "results = pool.map(load_audio, file_paths)\n",
        "\n",
        "# Close the pool of worker processes\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Extract the audio and sample rate from the results\n",
        "audio_abe, sr_abe = results[0]\n",
        "audio_abh, sr_abh = results[1]\n"
      ],
      "metadata": {
        "id": "fxTONDhJ9qqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st option\n",
        "# Play the audio\n",
        "Audio(data=audio_abe, rate=sr_abe)\n",
        "# Play the audio\n",
        "Audio(data=audio_abh, rate=sr_abh)"
      ],
      "metadata": {
        "id": "RP0lfll_iafr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "# Load the audio file with pydub\n",
        "audio_abe_pydub = AudioSegment.from_file(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\", format=\"ogg\")\n",
        "\n",
        "# Play the audio with pydub\n",
        "play(audio_abe_pydub)\n"
      ],
      "metadata": {
        "id": "vdQXMglDicFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3rd option\n",
        "import winsound\n",
        "\n",
        "# Load the audio file with librosa\n",
        "audio_abe, sr_abe = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\")\n",
        "\n",
        "# Play the audio with winsound\n",
        "winsound.PlaySound(audio_abe, winsound.SND_MEMORY)\n"
      ],
      "metadata": {
        "id": "8IMB0hqWAM-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Match the model's output with the bird species in the competition\n",
        "model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1')\n",
        "labels_path = hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1') + \"/assets/label.csv\""
      ],
      "metadata": {
        "id": "i2LD6FlVioIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1st option\n",
        "#  Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "    with open(labels_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        class_names = [mid for mid, desc in csv_reader]\n",
        "        return class_names[1:]\n",
        "\n",
        "## note that the bird classifier classifies a much larger set of birds than the\n",
        "## competition, so we need to load the model's set of class names or else our \n",
        "## indices will be off.\n",
        "classes = class_names_from_csv(labels_path)"
      ],
      "metadata": {
        "id": "CV4rQw5b76rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option \n",
        "import pandas as pd\n",
        "\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "    class_names = pd.read_csv(labels_path, usecols=[0, 1], header=None, index_col=0, squeeze=True).to_dict()\n",
        "    return list(class_names.values())\n",
        "\n",
        "classes = class_names_from_csv(labels_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "euYsLOQ1A5_m",
        "outputId": "ef295d13-69ba-4a67-ad36-aa3845d2f89f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-7a77ea74eaa0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2nd option\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\")\n",
        "train_metadata.head()\n",
        "competition_classes = sorted(train_metadata.primary_label.unique())\n",
        "â€‹\n",
        "forced_defaults = 0\n",
        "competition_class_map = []\n",
        "for c in competition_classes:\n",
        "    try:\n",
        "        i = classes.index(c)\n",
        "        competition_class_map.append(i)\n",
        "    except:\n",
        "        competition_class_map.append(0)\n",
        "        forced_defaults += 1\n",
        "        \n",
        "## this is the count of classes not supported by our pretrained model\n",
        "## you could choose to simply not predict these, set a default as above,\n",
        "## or create your own model using the pretrained model as a base.\n",
        "forced_defaults"
      ],
      "metadata": {
        "id": "HNRUSJKA7-3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option 2 \n",
        "import dask.dataframe as dd\n",
        "\n",
        "train_metadata = dd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\")\n",
        "train_metadata = train_metadata.compute()\n"
      ],
      "metadata": {
        "id": "9XlxLoIQBccT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option 3 \n",
        "train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\", usecols=[\"primary_label\"])\n"
      ],
      "metadata": {
        "id": "jhmabvzHBfXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "def frame_audio(\n",
        "      audio_array: np.ndarray,\n",
        "      window_size_s: float = 5.0,\n",
        "      hop_size_s: float = 5.0,\n",
        "      sample_rate = 32000,\n",
        "      ) -> np.ndarray:\n",
        "    \n",
        "    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
        "    \"\"\" using tf.signal \"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "        return audio_array[np.newaxis, :]\n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
        "    return framed_audio\n",
        "\n",
        "def ensure_sample_rate(waveform, original_sample_rate,\n",
        "                       desired_sample_rate=32000):\n",
        "    \"\"\"Resample waveform if required.\"\"\"\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n",
        "    return desired_sample_rate, waveform"
      ],
      "metadata": {
        "id": "e5FHB19T8EIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option\n",
        "import librosa\n",
        "\n",
        "def frame_audio(\n",
        "    audio_array: np.ndarray,\n",
        "    window_size_s: float = 5.0,\n",
        "    hop_size_s: float = 5.0,\n",
        "    sample_rate = 32000,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "        return audio_array[np.newaxis, :]\n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    framed_audio = librosa.util.frame(audio_array, frame_length, hop_length)\n",
        "    return framed_audio.T\n",
        "\n",
        "def ensure_sample_rate(waveform, original_sample_rate,\n",
        "                       desired_sample_rate=32000):\n",
        "    \"\"\"Resample waveform if required.\"\"\"\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        waveform = librosa.resample(waveform, original_sample_rate, desired_sample_rate)\n",
        "    return desired_sample_rate, waveform\n"
      ],
      "metadata": {
        "id": "VFUT8rGzB5Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st option\n",
        "audio, sample_rate = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/afghor1/XC156639.ogg\")\n",
        "sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
        "Audio(wav_data, rate=sample_rate)"
      ],
      "metadata": {
        "id": "m08QWSxm8XoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option\n",
        "import soundfile as sf\n",
        "\n",
        "def load_and_resample_audio(file_path, desired_sample_rate=32000):\n",
        "    \"\"\"Load audio file and resample if required.\"\"\"\n",
        "    audio, sample_rate = sf.read(file_path)\n",
        "    if sample_rate != desired_sample_rate:\n",
        "        audio = librosa.resample(audio.T, sample_rate, desired_sample_rate)\n",
        "        sample_rate = desired_sample_rate\n",
        "    return audio, sample_rate\n"
      ],
      "metadata": {
        "id": "pastH_86CIqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Make predictions\n",
        "fixed_tm = frame_audio(wav_data)\n",
        "logits, embeddings = model.infer_tf(fixed_tm[:1])\n",
        "probabilities = tf.nn.softmax(logits)\n",
        "argmax = np.argmax(probabilities)\n",
        "print(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")"
      ],
      "metadata": {
        "id": "n6Gry_GV8ebw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option \n",
        "def batch_frame_audio(audio_array: np.ndarray, batch_size: int, window_size_s: float = 5.0,\n",
        "                      hop_size_s: float = 5.0, sample_rate=32000) -> np.ndarray:\n",
        "    \"\"\"Helper function for batching and framing audio for inference.\"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "        return audio_array[np.newaxis, :]\n",
        "    \n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    frames = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
        "    \n",
        "    num_frames = frames.shape[0]\n",
        "    num_batches = int(np.ceil(num_frames / batch_size))\n",
        "    padded_frames = np.zeros((num_batches * batch_size, frame_length))\n",
        "    padded_frames[:num_frames] = frames\n",
        "    \n",
        "    batched_frames = np.reshape(padded_frames, (num_batches, batch_size, frame_length))\n",
        "    return batched_frames\n",
        "\n",
        "\n",
        "def predict_audio_class(model, audio, batch_size=16):\n",
        "    \"\"\"Predict the class of an audio sample using a pre-trained model.\"\"\"\n",
        "    fixed_audio, sample_rate = load_and_resample_audio(audio)\n",
        "    frames = batch_frame_audio(fixed_audio, batch_size)\n",
        "    probabilities = []\n",
        "    for batch in frames:\n",
        "        logits, embeddings = model.infer_tf(batch)\n",
        "        batch_probabilities = tf.nn.softmax(logits)\n",
        "        probabilities.append(batch_probabilities)\n",
        "    probabilities = tf.concat(probabilities, axis=0)\n",
        "    argmax = np.argmax(probabilities, axis=1)\n",
        "    classes = class_names_from_csv(labels_path)\n",
        "    class_names = [classes[i] for i in argmax]\n",
        "    return class_names, probabilities\n"
      ],
      "metadata": {
        "id": "7RBdBn1RDBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st option\n",
        "def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n",
        "    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n",
        "    \n",
        "    audio, sample_rate = librosa.load(filename)\n",
        "    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
        "    \n",
        "    fixed_tm = frame_audio(wav_data)\n",
        "    \n",
        "    frame = 5\n",
        "    all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n",
        "    for window in fixed_tm[1:]:\n",
        "        if frame_limit_secs and frame > frame_limit_secs:\n",
        "            continue\n",
        "        \n",
        "        logits, embeddings = model.infer_tf(window[np.newaxis, :])\n",
        "        all_logits = np.concatenate([all_logits, logits], axis=0)\n",
        "        frame += 5\n",
        "    \n",
        "    frame = 5\n",
        "    all_probabilities = []\n",
        "    for frame_logits in all_logits:\n",
        "        probabilities = tf.nn.softmax(frame_logits).numpy()\n",
        "        \n",
        "        ## set the appropriate row in the sample submission\n",
        "        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame), competition_classes] = probabilities[competition_class_map]\n",
        "        frame += 5"
      ],
      "metadata": {
        "id": "4wV6j4HE8q-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd option \n",
        "def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n",
        "    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n",
        "    \n",
        "    audio, sample_rate = librosa.load(filename)\n",
        "    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
        "    \n",
        "    fixed_tm = frame_audio(wav_data)\n",
        "    \n",
        "    frame = 5\n",
        "    all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n",
        "    for window in fixed_tm[1:]:\n",
        "        if frame_limit_secs and frame > frame_limit_secs:\n",
        "            continue\n",
        "        \n",
        "        logits, embeddings = model.infer_tf(window[np.newaxis, :])\n",
        "        all_logits = np.concatenate([all_logits, logits], axis=0)\n",
        "        frame += 5\n",
        "    \n",
        "    frame = 5\n",
        "    all_probabilities = []\n",
        "    for frame_logits in all_logits:\n",
        "        probabilities = tf.nn.softmax(frame_logits).numpy()\n",
        "        \n",
        "        ## set the appropriate row in the sample submission\n",
        "        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame), competition_classes] = probabilities[competition_class_map]\n",
        "        frame += 5"
      ],
      "metadata": {
        "id": "Fk6SZ9SwDd8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Generate a submission\n",
        "test_samples = list(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\n",
        "test_samples"
      ],
      "metadata": {
        "id": "ix4d3ERe8wQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub = pd.read_csv(\"/kaggle/input/birdclef-2023/sample_submission.csv\")\n",
        "sample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\n",
        "sample_sub.head()"
      ],
      "metadata": {
        "id": "y9l8Krk_84_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_limit_secs = 15 if sample_sub.shape[0] == 3 else None\n",
        "for sample_filename in test_samples:\n",
        "    predict_for_sample(sample_filename, sample_sub, frame_limit_secs=15)"
      ],
      "metadata": {
        "id": "zeFM2lzZ88bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub"
      ],
      "metadata": {
        "id": "TiXWWuPv8_nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "_NvYeLH99EPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}